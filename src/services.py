from __future__ import annotations

import json
import re
from typing import Any, Dict, List, Optional

from loguru import logger

from retriever import retriever
from llm_config import llm_config


class LLMService:
    """LLM å‘¼ã³å‡ºã—ã‚’æ‹…ã†è–„ã„ã‚µãƒ¼ãƒ“ã‚¹ã€‚UI ã«ä¾å­˜ã—ãªã„ã€‚"""

    def generate(self, messages: List[Dict[str, str]], temperature: float = 0.3) -> str:
        return llm_config.generate_response(messages, temperature=temperature)

    def stream(self, messages: List[Dict[str, str]], temperature: float = 0.3):
        return llm_config.generate_response_stream(messages, temperature=temperature)


class AnalysisService:
    """ã‚¢ãƒ—ãƒªã®ä¸­æ ¸ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’é›†ç´„ã€‚UI ã‹ã‚‰ç‹¬ç«‹ã€‚"""

    def __init__(self, llm: Optional[LLMService] = None) -> None:
        self.llm = llm or LLMService()

    # --- Retrieval è£œåŠ© ---
    def get_available_indicators_for_query(self, query: str) -> str:
        try:
            if retriever.df is None:
                retriever.load_vector_database()

            logger.info(f"ğŸ” æŒ‡æ¨™ä¾‹å–å¾—é–‹å§‹: '{query}'")
            search_results = retriever.hybrid_search(query, top_k=40)

            bunya_groups: Dict[str, List[str]] = {}
            for result in search_results:
                bunya = result["bunya_name"]
                bunya_groups.setdefault(bunya, []).append(result["koumoku_name_full"])

            for bunya in list(bunya_groups.keys()):
                bunya_indicators = (
                    retriever.df[retriever.df["bunya_name"] == bunya]["koumoku_name_full"].tolist()
                )
                existing = set(bunya_groups[bunya])
                additional = [ind for ind in bunya_indicators if ind not in existing][:10]
                bunya_groups[bunya].extend(additional)

            indicator_examples: List[str] = []
            for bunya, indicators in bunya_groups.items():
                indicator_examples.append(
                    f"ã€{bunya}ã€‘({len(indicators)}ä»¶åˆ©ç”¨å¯èƒ½): {', '.join(indicators[:15])}"
                )

            return "\n".join(indicator_examples)
        except Exception as e:
            return f"æŒ‡æ¨™ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"

    # --- LLM ç”Ÿæˆç³» ---
    def generate_analysis_plan(self, query: str) -> Optional[Dict[str, Any]]:
        logger.info(f"ğŸ¤– åˆ†æè¨ˆç”»ã®ç”Ÿæˆé–‹å§‹: '{query}'")
        available_indicators = self.get_available_indicators_for_query(query)

        system_prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€è¤‡æ•°ã®ã€Œåˆ†æè¦³ç‚¹ã€ã¨ã€å„è¦³ç‚¹ã‚’æ¢ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã€ŒæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—æ¡ˆã€ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

# æŒ‡ç¤º
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€åŒ…æ‹¬çš„ãªåˆ†æè¨ˆç”»ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
åˆ†æè¨ˆç”»ã«ã¯ã€8ã€œ10å€‹ã®ã€Œåˆ†æè¦³ç‚¹ï¼ˆperspectivesï¼‰ã€ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
å„ã€Œåˆ†æè¦³ç‚¹ã€ã«ã¯ã€ãã®è¦³ç‚¹ã§å…·ä½“çš„ã«ä½•ã‚’è¦‹ã‚‹ã¹ãã‹ã‚’ç¤ºã™ã€ŒæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—æ¡ˆï¼ˆsuggested_groupsï¼‰ã€ã‚’2ã€œ3å€‹å«ã‚ã¦ãã ã•ã„ã€‚

# åˆ©ç”¨å¯èƒ½ãªçµ±è¨ˆæŒ‡æ¨™ã®ä¾‹
{available_indicators}

# å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšã“ã®JSONæ§‹é€ ã«å¾“ã†ã“ã¨ï¼‰
{{
  "analysis_plan": {{
    "perspectives": [
      {{
        "perspective_title": "ï¼ˆä¾‹ï¼‰æ•™è‚²ç’°å¢ƒã®å……å®Ÿåº¦",
        "perspective_description": "åœ°åŸŸã®æ•™è‚²æ°´æº–ã‚„å­è‚²ã¦ä¸–ä»£ã¸ã®æ•™è‚²æ”¯æ´ãŒã©ã®ç¨‹åº¦æ‰‹åšã„ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è¦³ç‚¹ã§ã™ã€‚",
        "suggested_groups": [
          {{
            "group_title": "ï¼ˆä¾‹ï¼‰å­¦æ ¡æ•™è‚²ã¨æ–½è¨­",
            "group_description": "å…¬ç«‹å­¦æ ¡ã®æ•°ã€æ•™å“¡ä¸€äººå½“ãŸã‚Šã®ç”Ÿå¾’æ•°ã€å›³æ›¸é¤¨ã‚„ä½“è‚²é¤¨ã¨ã„ã£ãŸæ–½è¨­ã®çŠ¶æ³ã‹ã‚‰ã€åŸºç¤çš„ãªæ•™è‚²ç’°å¢ƒã®è³ªã‚’æŠŠæ¡ã—ã¾ã™ã€‚"
          }},
          {{
            "group_title": "ï¼ˆä¾‹ï¼‰ä¿è‚²ãƒ»å¾…æ©Ÿå…ç«¥å•é¡Œ",
            "group_description": "ä¿è‚²æ‰€ã®æ•°ã‚„å¾…æ©Ÿå…ç«¥ã®çŠ¶æ³ã§ã™ã€‚ã“ã‚ŒãŒæ”¹å–„ã•ã‚Œã‚Œã°ã€å…±åƒãä¸–å¸¯ãŒå®‰å¿ƒã—ã¦å­è‚²ã¦ã§ãã‚‹ç’°å¢ƒãŒæ•´ã£ã¦ã„ã‚‹ã¨è¨€ãˆã¾ã™ã€‚"
          }}
        ]
      }}
    ]
  }}
}}

# åˆ¶ç´„
- JSONå½¢å¼ä»¥å¤–ã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
- èª¬æ˜æ–‡ã¯ä¸å¯§ãªã€Œã§ã™ã¾ã™èª¿ã€ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã—ã‚„ã™ã„ã‚ˆã†ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""
        user_prompt = (
            f"ä»¥ä¸‹ã®è³ªå•ã«ã¤ã„ã¦ã€è©³ç´°ãªåˆ†æè¨ˆç”»ã‚’JSONå½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ï¼š\n\n{query}"
        )

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
            response = self.llm.generate(messages, temperature=0.2)

            json_match = re.search(r"\{.*\}", response, re.DOTALL)
            if json_match:
                result: Dict[str, Any] = json.loads(json_match.group())
                if "analysis_plan" in result and "perspectives" in result["analysis_plan"]:
                    result["analysis_plan"]["perspectives"] = result["analysis_plan"][
                        "perspectives"
                    ][:10]
                logger.info("âœ… åˆ†æè¨ˆç”»ã®ç”Ÿæˆã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                return result
            else:
                logger.error(f"âŒ åˆ†æè¨ˆç”»ã®JSONç”Ÿæˆã«å¤±æ•—: {response[:500]}...")
                return None
        except Exception as e:
            logger.error(f"âŒ åˆ†æè¨ˆç”»ã®ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def stream_analysis_plan_raw(self, query: str):
        available_indicators = self.get_available_indicators_for_query(query)
        system_prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€è¤‡æ•°ã®ã€Œåˆ†æè¦³ç‚¹ã€ã¨ã€å„è¦³ç‚¹ã‚’æ¢ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã€ŒæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—æ¡ˆã€ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

# æŒ‡ç¤º
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€åŒ…æ‹¬çš„ãªåˆ†æè¨ˆç”»ã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
åˆ†æè¨ˆç”»ã«ã¯ã€8ã€œ10å€‹ã®ã€Œåˆ†æè¦³ç‚¹ï¼ˆperspectivesï¼‰ã€ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
å„ã€Œåˆ†æè¦³ç‚¹ã€ã«ã¯ã€ãã®è¦³ç‚¹ã§å…·ä½“çš„ã«ä½•ã‚’è¦‹ã‚‹ã¹ãã‹ã‚’ç¤ºã™ã€ŒæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—æ¡ˆï¼ˆsuggested_groupsï¼‰ã€ã‚’2ã€œ3å€‹å«ã‚ã¦ãã ã•ã„ã€‚

# åˆ©ç”¨å¯èƒ½ãªçµ±è¨ˆæŒ‡æ¨™ã®ä¾‹
{available_indicators}

# å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšã“ã®JSONæ§‹é€ ã«å¾“ã†ã“ã¨ï¼‰
{{
  "analysis_plan": {{
    "perspectives": [
      {{
        "perspective_title": "ï¼ˆä¾‹ï¼‰æ•™è‚²ç’°å¢ƒã®å……å®Ÿåº¦",
        "perspective_description": "åœ°åŸŸã®æ•™è‚²æ°´æº–ã‚„å­è‚²ã¦ä¸–ä»£ã¸ã®æ•™è‚²æ”¯æ´ãŒã©ã®ç¨‹åº¦æ‰‹åšã„ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è¦³ç‚¹ã§ã™ã€‚",
        "suggested_groups": [
          {{
            "group_title": "ï¼ˆä¾‹ï¼‰å­¦æ ¡æ•™è‚²ã¨æ–½è¨­",
            "group_description": "å…¬ç«‹å­¦æ ¡ã®æ•°ã€æ•™å“¡ä¸€äººå½“ãŸã‚Šã®ç”Ÿå¾’æ•°ã€å›³æ›¸é¤¨ã‚„ä½“è‚²é¤¨ã¨ã„ã£ãŸæ–½è¨­ã®çŠ¶æ³ã‹ã‚‰ã€åŸºç¤çš„ãªæ•™è‚²ç’°å¢ƒã®è³ªã‚’æŠŠæ¡ã—ã¾ã™ã€‚"
          }},
          {{
            "group_title": "ï¼ˆä¾‹ï¼‰ä¿è‚²ãƒ»å¾…æ©Ÿå…ç«¥å•é¡Œ",
            "group_description": "ä¿è‚²æ‰€ã®æ•°ã‚„å¾…æ©Ÿå…ç«¥ã®çŠ¶æ³ã§ã™ã€‚ã“ã‚ŒãŒæ”¹å–„ã•ã‚Œã‚Œã°ã€å…±åƒãä¸–å¸¯ãŒå®‰å¿ƒã—ã¦å­è‚²ã¦ã§ãã‚‹ç’°å¢ƒãŒæ•´ã£ã¦ã„ã‚‹ã¨è¨€ãˆã¾ã™ã€‚"
          }}
        ]
      }}
    ]
  }}
}}

# åˆ¶ç´„
- JSONå½¢å¼ä»¥å¤–ã¯çµ¶å¯¾ã«å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚
- èª¬æ˜æ–‡ã¯ä¸å¯§ãªã€Œã§ã™ã¾ã™èª¿ã€ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ã—ã‚„ã™ã„ã‚ˆã†ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""
        user_prompt = f"ä»¥ä¸‹ã®è³ªå•ã«ã¤ã„ã¦ã€è©³ç´°ãªåˆ†æè¨ˆç”»ã‚’JSONå½¢å¼ã§ææ¡ˆã—ã¦ãã ã•ã„ï¼š\n\n{query}"
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
        return self.llm.stream(messages, temperature=0.2)

    def generate_group_summary(self, group_indicators: List[Dict[str, Any]], user_query: str) -> str:
        logger.info(
            f"ğŸ¤– ã‚°ãƒ«ãƒ¼ãƒ—è¦ç´„ç”Ÿæˆé–‹å§‹: '{user_query}' for {len(group_indicators)} indicators"
        )

        indicator_names = [i.get("koumoku_name_full", "") for i in group_indicators]
        representative = group_indicators[0] if group_indicators else {}
        bunya_info = (
            f"{representative.get('bunya_name', '')} > {representative.get('chuubunrui_name', '')} > {representative.get('shoubunrui_name', '')}"
        )

        system_prompt = f"""ã‚ãªãŸã¯çµ±è¨ˆåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ãŒã©ã®ã‚ˆã†ãªåˆ†æã®åˆ‡ã‚Šå£ã‚’æä¾›ã™ã‚‹ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª**: {user_query}

**æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã«å«ã¾ã‚Œã‚‹æŒ‡æ¨™**: {', '.join(indicator_names[:10])}{'...' if len(indicator_names) > 10 else ''}

**åˆ†é‡**: {bunya_info}

**æŒ‡æ¨™æ•°**: {len(group_indicators)}ä»¶

ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æŒ‡æ¨™ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¦ç´„æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã«å¯¾ã—ã€ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒã©ã®ã‚ˆã†ãªåˆ†æã®åˆ‡ã‚Šå£ã‚’æä¾›ã™ã‚‹ã‹
- ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æŒ‡æ¨™ã‚’è¦‹ã‚‹ã“ã¨ã§ä½•ãŒã‚ã‹ã‚‹ã®ã‹
- ãªãœã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã«é‡è¦ãªã®ã‹
- è¦ç´„æ–‡ã¯150-250æ–‡å­—ç¨‹åº¦ã§ã€ä¸å¯§ãªã€Œã§ã™ã¾ã™èª¿ã€ã§è¨˜è¿°

å‡ºåŠ›ã¯è¦ç´„æ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã‚„ä»–ã®å½¢å¼ã¯ä¸è¦ã§ã™ã€‚"""

        user_prompt = (
            f"ä¸Šè¨˜ã®æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã€Œ{user_query}ã€ã«å¯¾ã™ã‚‹è¦ç´„èª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        )

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
            response = self.llm.generate(messages, temperature=0.3)
            logger.info("âœ… ã‚°ãƒ«ãƒ¼ãƒ—è¦ç´„ç”ŸæˆæˆåŠŸ")
            return response.strip()
        except Exception as e:
            logger.error(f"âŒ ã‚°ãƒ«ãƒ¼ãƒ—è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return "ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æŒ‡æ¨™ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã«é–¢é€£ã™ã‚‹é‡è¦ãªçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"

    def stream_group_summary(self, group_indicators: List[Dict[str, Any]], user_query: str):
        indicator_names = [i.get("koumoku_name_full", "") for i in group_indicators]
        representative = group_indicators[0] if group_indicators else {}
        bunya_info = (
            f"{representative.get('bunya_name', '')} > {representative.get('chuubunrui_name', '')} > {representative.get('shoubunrui_name', '')}"
        )
        system_prompt = f"""ã‚ãªãŸã¯çµ±è¨ˆåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ãŒã©ã®ã‚ˆã†ãªåˆ†æã®åˆ‡ã‚Šå£ã‚’æä¾›ã™ã‚‹ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª**: {user_query}

**æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã«å«ã¾ã‚Œã‚‹æŒ‡æ¨™**: {', '.join(indicator_names[:10])}{'...' if len(indicator_names) > 10 else ''}

**åˆ†é‡**: {bunya_info}

**æŒ‡æ¨™æ•°**: {len(group_indicators)}ä»¶

ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æŒ‡æ¨™ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¦ç´„æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã«å¯¾ã—ã€ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒã©ã®ã‚ˆã†ãªåˆ†æã®åˆ‡ã‚Šå£ã‚’æä¾›ã™ã‚‹ã‹
- ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®æŒ‡æ¨™ã‚’è¦‹ã‚‹ã“ã¨ã§ä½•ãŒã‚ã‹ã‚‹ã®ã‹
- ãªãœã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒäº‹ã«é‡è¦ãªã®ã‹
- è¦ç´„æ–‡ã¯150-250æ–‡å­—ç¨‹åº¦ã§ã€ä¸å¯§ãªã€Œã§ã™ã¾ã™èª¿ã€ã§è¨˜è¿°

å‡ºåŠ›ã¯è¦ç´„æ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã‚„ä»–ã®å½¢å¼ã¯ä¸è¦ã§ã™ã€‚"""
        user_prompt = (
            f"ä¸Šè¨˜ã®æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã€Œ{user_query}ã€ã«å¯¾ã™ã‚‹è¦ç´„èª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
        return self.llm.stream(messages, temperature=0.3)

    def generate_indicator_explanations(
        self, user_query: str, indicators_list: List[Dict[str, Any]]
    ) -> Dict[str, str]:
        logger.info(
            f"ğŸ¤– æŒ‡æ¨™èª¬æ˜æ–‡ç”Ÿæˆé–‹å§‹: '{user_query}' for {len(indicators_list)} indicators"
        )

        indicator_names = [i.get("koumoku_name_full", "") for i in indicators_list]
        system_prompt = f"""ã‚ãªãŸã¯çµ±è¨ˆåˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€å„çµ±è¨ˆæŒ‡æ¨™ãŒãªãœé‡è¦ãªã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª**: {user_query}

**çµ±è¨ˆæŒ‡æ¨™ãƒªã‚¹ãƒˆ**: {', '.join(indicator_names)}

å„çµ±è¨ˆæŒ‡æ¨™ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ç°¡æ½”ã§è¦ªåˆ‡ãªèª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
- ã“ã®æŒ‡æ¨™ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«ã©ã®ã‚ˆã†ã«é–¢é€£ã™ã‚‹ã®ã‹
- ã“ã®æŒ‡æ¨™ã‚’è¦‹ã‚‹ã“ã¨ã§ä½•ãŒåˆ†ã‹ã‚‹ã®ã‹
- ãªãœã“ã®æŒ‡æ¨™ãŒé‡è¦ãªã®ã‹
- 1ã¤ã®èª¬æ˜æ–‡ã¯60-80æ–‡å­—ç¨‹åº¦ã§ã€Œã“ã®æŒ‡æ¨™ã¯...ã€ã§å§‹ã¾ã‚‹ä¸å¯§ãªæ–‡ç« 

å‡ºåŠ›ã¯å¿…ãšJSONå½¢å¼ã§ã€ä»¥ä¸‹ã®æ§‹é€ ã«å¾“ã£ã¦ãã ã•ã„ï¼š
{{
  "æŒ‡æ¨™å1": "ã“ã®æŒ‡æ¨™ã¯...",
  "æŒ‡æ¨™å2": "ã“ã®æŒ‡æ¨™ã¯...",
  ...
}}

**å¿…é ˆè¦ä»¶**ï¼š
- ã‚­ãƒ¼ã¯ä¸Šè¨˜ãƒªã‚¹ãƒˆã®æŒ‡æ¨™åã¨å®Œå…¨ã«ä¸€è‡´ã•ã›ã¦ãã ã•ã„
- å€¤ã¯60-80æ–‡å­—ç¨‹åº¦ã§ã€Œã“ã®æŒ‡æ¨™ã¯...ã€ã§å§‹ã¾ã‚‹èª¬æ˜æ–‡ã«ã—ã¦ãã ã•ã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦åˆ†ã‹ã‚Šã‚„ã™ãè¦ªåˆ‡ãªèª¬æ˜ã«ã—ã¦ãã ã•ã„
- JSONå½¢å¼ä»¥å¤–ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„"""

        user_prompt = (
            f"ä¸Šè¨˜ã®çµ±è¨ˆæŒ‡æ¨™ã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã€Œ{user_query}ã€ã¨ã®é–¢é€£æ€§ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        )

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
            response = self.llm.generate(messages, temperature=0.3)
            logger.info(f"ğŸ” æŒ‡æ¨™èª¬æ˜æ–‡LLMå¿œç­”ã®æœ€åˆã®500æ–‡å­—: {response[:500]}")

            json_match = re.search(r"\{.*\}", response, re.DOTALL)
            if json_match:
                parsed_json = json.loads(json_match.group())
                logger.info(f"âœ… æŒ‡æ¨™èª¬æ˜æ–‡ç”ŸæˆæˆåŠŸ: {len(parsed_json)}ä»¶")
                return parsed_json
            else:
                logger.error(f"âŒ æœ‰åŠ¹ãªJSONãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {response[:500]}")
                return {}
        except Exception as e:
            logger.error(f"âŒ æŒ‡æ¨™èª¬æ˜æ–‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}

    def generate_indicator_groups_for_perspective(
        self, perspective_title: str
    ) -> Optional[Dict[str, Any]]:
        logger.info(f"ğŸ¤– æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ç”Ÿæˆé–‹å§‹: '{perspective_title}'")
        try:
            if retriever.df is None:
                retriever.load_vector_database()

            logger.info("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—A: hybrid_searchã§é–¢é€£æŒ‡æ¨™ã‚’å–å¾—")
            search_results = retriever.hybrid_search(perspective_title, top_k=80)
            if not search_results:
                logger.error("âŒ hybrid_searchã§çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None

            related_indicator_names = [r["koumoku_name_full"] for r in search_results]
            logger.info(f"ğŸ“Š hybrid_searchã§å–å¾—ã—ãŸé–¢é€£æŒ‡æ¨™æ•°: {len(related_indicator_names)}ä»¶")

            df_filtered = retriever.df[retriever.df["koumoku_name_full"].isin(related_indicator_names)]
            logger.info(f"ğŸ“‹ ä¸€æ¬¡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿DataFrame: {len(df_filtered)}è¡Œ")
            if df_filtered.empty:
                logger.warning("âš ï¸ ä¸€æ¬¡ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿DataFrameãŒç©ºã§ã™")
                return None

            logger.info("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—B: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªgroup_codeã‚’æŠ½å‡º")
            group_codes = df_filtered["group_code"].dropna().unique()
            logger.info(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸã‚°ãƒ«ãƒ¼ãƒ—ã‚³ãƒ¼ãƒ‰: {group_codes.tolist()}")
            logger.info(f"ğŸ” ã‚°ãƒ«ãƒ¼ãƒ—ã‚³ãƒ¼ãƒ‰æ•°: {len(group_codes)}ä»¶")

            group_indicators: List[Dict[str, Any]] = []
            for group_code in sorted(group_codes):
                group_code_str = str(group_code)

                representative = retriever.df[
                    retriever.df["koumoku_code"].astype(str) == group_code_str
                ]
                if not representative.empty:
                    row = representative.iloc(0)[0] if hasattr(representative, "iloc") else representative.iloc[0]
                    group_indicators.append(
                        {
                            "group_code": group_code_str,
                            "title": row["koumoku_name_full"],
                            "description": f"ã€Œ{row['koumoku_name_full']}ã€ã‚°ãƒ«ãƒ¼ãƒ—ã«å«ã¾ã‚Œã‚‹å…¨ã¦ã®é–¢é€£æŒ‡æ¨™",
                        }
                    )
                else:
                    fallback_indicators = df_filtered[
                        df_filtered["group_code"].astype(str) == group_code_str
                    ]
                    if not fallback_indicators.empty:
                        row = fallback_indicators.iloc[0]
                        group_indicators.append(
                            {
                                "group_code": group_code_str,
                                "title": f"{row['koumoku_name_full']}é–¢é€£ã‚°ãƒ«ãƒ¼ãƒ—",
                                "description": f"ã€Œ{row['koumoku_name_full']}ã€é–¢é€£ã®æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—",
                            }
                        )

            group_indicators = group_indicators[:15]
            logger.info(f"âœ… {len(group_indicators)}å€‹ã®æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç”Ÿæˆ")
            return {"groups": group_indicators}
        except Exception as e:
            logger.error(f"âŒ æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    # é€Ÿåº¦æ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆäº’æ›ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä½¿ç”¨ï¼‰
    def generate_ai_analysis(self, query: str) -> Optional[Dict[str, Any]]:
        """é€Ÿåº¦ãƒ†ã‚¹ãƒˆäº’æ›ã®ç°¡æ˜“ APIã€‚

        è¿”å´å½¢å¼ã¯ { 'analysis_perspectives': [ { 'recommended_indicators': [...] }, ... ] }
        ã«æ•´å½¢ã™ã‚‹ã€‚
        """
        plan = self.generate_analysis_plan(query)
        if not plan or "analysis_plan" not in plan:
            return None

        perspectives = plan["analysis_plan"].get("perspectives", [])
        normalized: List[Dict[str, Any]] = []
        for p in perspectives:
            groups = p.get("suggested_groups", [])
            normalized.append({"recommended_indicators": groups})
        return {"analysis_perspectives": normalized}

